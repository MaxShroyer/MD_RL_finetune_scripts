{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BallHolder RL Pipeline\\n\n",
    "\\n\n",
    "Run order: analyze dataset -> create splits (+ optional HF upload) -> analyze splits -> train -> benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup (run once)\\n\n",
    "!pip install -q datasets pillow numpy scipy wandb python-dotenv\\n\n",
    "\\n\n",
    "# Ensure your keys exist in .env or pass --env-file to each command\\n\n",
    "!cat .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Analyze original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\\n\n",
    "!python analyze_ballholder_dataset.py \\\n",
    "  --dataset-name maxs-m87/Ball-Holder \\\n",
    "  --split train \\\n",
    "  --streaming \\\n",
    "  --out-json outputs/ballholder_dataset_stats_raw.json\\n\n",
    "\\n\n",
    "# Recommended (larger sample + shuffle)\\n\n",
    "!python analyze_ballholder_dataset.py \\\n",
    "  --dataset-name maxs-m87/Ball-Holder \\\n",
    "  --split train \\\n",
    "  --streaming --shuffle --buffer-size 5000 --seed 42 \\\n",
    "  --max-samples 100000 \\\n",
    "  --out-json outputs/ballholder_dataset_stats_raw.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create splits (and optionally upload to HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default local split build\\n\n",
    "!python create_ballholder_splits.py \\\n",
    "  --dataset maxs-m87/Ball-Holder \\\n",
    "  --split train \\\n",
    "  --val-fraction 0.10 \\\n",
    "  --holdout-count 1000 \\\n",
    "  --empty-fraction 0.25\\n\n",
    "\\n\n",
    "# Recommended: also push to hub (edit repo name)\\n\n",
    "!python create_ballholder_splits.py \\\n",
    "  --dataset maxs-m87/Ball-Holder \\\n",
    "  --split train \\\n",
    "  --val-fraction 0.10 \\\n",
    "  --holdout-count 1000 \\\n",
    "  --empty-fraction 0.25 \\\n",
    "  --push-to-hub maxs-m87/Ball-Holder-splits-v1 \\\n",
    "  --hub-val-split validation \\\n",
    "  --hub-post-val-split test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Analyze splits to validate positive/negative balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze locally saved train/val/post_val splits\\n\n",
    "!python analyze_ballholder_dataset.py \\\n",
    "  --dataset-path outputs/maxs-m87_Ball-Holder_splits \\\n",
    "  --all-splits \\\n",
    "  --out-json outputs/ballholder_dataset_stats_splits.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Train (with W&B metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default train command\\n\n",
    "!python train_ballholder.py \\\n",
    "  --dataset-path outputs/maxs-m87_Ball-Holder_splits \\\n",
    "  --split train \\\n",
    "  --val-split val \\\n",
    "  --num-steps 1000 \\\n",
    "  --batch-size 8 \\\n",
    "  --group-size 4 \\\n",
    "  --max-objects 1 \\\n",
    "  --best-metric eval_miou \\\n",
    "  --eval-every 25 \\\n",
    "  --save-every 25 \\\n",
    "  --wandb-project moondream-ballholder-rl\\n\n",
    "\\n\n",
    "# Recommended stronger run\\n\n",
    "!python train_ballholder.py \\\n",
    "  --dataset-path outputs/maxs-m87_Ball-Holder_splits \\\n",
    "  --split train \\\n",
    "  --val-split val \\\n",
    "  --num-steps 1500 \\\n",
    "  --batch-size 8 \\\n",
    "  --group-size 8 \\\n",
    "  --lr 0.002 \\\n",
    "  --max-objects 1 \\\n",
    "  --augment-prob 0.9 \\\n",
    "  --empty-keep-prob 0.5 \\\n",
    "  --off-policy \\\n",
    "  --best-metric eval_miou \\\n",
    "  --eval-every 25 \\\n",
    "  --save-every 25 \\\n",
    "  --eval-max-samples 2000 \\\n",
    "  --wandb-project moondream-ballholder-rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Benchmark on unseen split (`post_val`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace MODEL with your finetuned checkpoint, e.g. moondream3-preview/<finetune_id>@<step>\\n\n",
    "MODEL = \"moondream3-preview\"\\n\n",
    "\\n\n",
    "# Option A: /detect inference (baseline model or deployed checkpoint)\\n\n",
    "!python benchmark_ballholder.py \\\\\\n\n",
    "  --model {MODEL} \\\\\\n\n",
    "  --dataset-path outputs/maxs-m87_Ball-Holder_splits \\\\\\n\n",
    "  --split post_val \\\\\\n\n",
    "  --max-objects 1 \\\\\\n\n",
    "  --iou-threshold 0.5 \\\\\\n\n",
    "  --save-viz \\\\\\n\n",
    "  --viz-limit 100 \\\\\\n\n",
    "  --out-json outputs/benchmark_metrics_post_val_detect_api.json\\n\n",
    "\\n\n",
    "# Option B: RL finetune inference via tuning interface (latest finetune state)\\n\n",
    "FINETUNE_ID = \"\"\\n\n",
    "!python benchmark_ballholder.py \\\\\\n\n",
    "  --finetune-id {FINETUNE_ID} \\\\\\n\n",
    "  --dataset-path outputs/maxs-m87_Ball-Holder_splits \\\\\\n\n",
    "  --split post_val \\\\\\n\n",
    "  --batch-size 16 --max-workers 16 \\\\\\n\n",
    "  --max-objects 1 \\\\\\n\n",
    "  --iou-threshold 0.5 \\\\\\n\n",
    "  --save-viz \\\\\\n\n",
    "  --viz-limit 100 \\\\\\n\n",
    "  --out-json outputs/benchmark_metrics_post_val_tuning_interface.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
